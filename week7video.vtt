WEBVTT

1
00:00:02.310 --> 00:00:11.400
Michael Franz: Hello everybody and welcome to Week seven or at least the end of week seven or the middle of Week seven depending on when you're listening to this and

2
00:00:12.420 --> 00:00:27.780
Michael Franz: Coming back after Fall break we're moving into ESSENTIALLY, TWO WEEKS OF DISCUSSION AROUND exit polling and I'm sorry polling and an exit polling. So the broader enterprise of serving voters in a

3
00:00:29.220 --> 00:00:40.380
Michael Franz: In a constituency in a geographic area state or a congressional district and I want to walk us through what I call some of the nuts and bolts of

4
00:00:40.860 --> 00:00:49.290
Michael Franz: Polling the the opportunities and the challenges, some of which was raised in the article for today by sunshine Hill August, but also

5
00:00:49.860 --> 00:00:56.070
Michael Franz: Doesn't get a necessarily a full and lengthy description. And so I want to walk us through some of these

6
00:00:56.730 --> 00:01:10.470
Michael Franz: Some of these challenges. Some of these opportunities, show us some analysis from previous elections and and lay out what I think of the key features to look at in a in a poll, or in a set of polls.

7
00:01:11.400 --> 00:01:20.280
Michael Franz: So let me share my screen to bring up this PowerPoint presentation and then I'll excuse me all alum.

8
00:01:21.690 --> 00:01:23.970
Michael Franz: Play the presentation and

9
00:01:27.210 --> 00:01:35.640
Michael Franz: The title of it is, sort of, you know, not super important. But, you know, can political polling be trusted is really the underlying question and

10
00:01:36.120 --> 00:01:44.010
Michael Franz: I'm going to be talking about some nuts and bolts, as I said, and there's a lot of interesting ways to think about polling.

11
00:01:44.550 --> 00:01:53.370
Michael Franz: But one of the things I want to start with is, well, one is this cartoon maybe gets to my final point or today, which is that we can spend

12
00:01:53.970 --> 00:02:04.200
Michael Franz: A lot of time talking about the mechanics of pole collection data collection. But then at the end of the day. There's also the questions we asked and those need to be

13
00:02:06.330 --> 00:02:13.290
Michael Franz: Those needs to be good ones. And then we can ask bad questions or vague questions and then the results we get back are not very helpful at all.

14
00:02:15.510 --> 00:02:20.340
Michael Franz: But the first thing I want to point out is that polling can be a very valuable and important.

15
00:02:21.690 --> 00:02:30.750
Michael Franz: Resource I called it in the module, the structure of the module. And one of my sections that a prime set of primary documents in the history of

16
00:02:31.140 --> 00:02:37.500
Michael Franz: American elections and if you look at this graph, which I'll explain you get a sense of, of the awesome

17
00:02:38.490 --> 00:02:46.650
Michael Franz: capacities of polling and combining and looking at pulls over time. These are Gallup polls Gallup has been in the industry for

18
00:02:47.250 --> 00:03:03.690
Michael Franz: 70 more than 70 years and has been consistently pulling Americans asking the same questions they asked lots of different questions and lots of different polls, but they asked a lot of the same questions over time. And so we have decades and decades and decades of polling data.

19
00:03:04.830 --> 00:03:17.550
Michael Franz: These are aggregated for us by pollster calm, which the article mentions as one of the polling aggregators they're no longer an operation. And so you'll see that this time series ends in 2017

20
00:03:18.060 --> 00:03:23.160
Michael Franz: We don't have updated data as easily accessible from polling aggregators

21
00:03:23.700 --> 00:03:36.480
Michael Franz: Real Clear Politics and and 538 to aggregate poles for us. They didn't split them out as easily as pollster did pulsar.com is still a websites, you can go take a look at it. But they don't update their data anymore.

22
00:03:37.020 --> 00:03:44.460
Michael Franz: These data that underlie this graph still exist past 2017 but they're just not easily sortable in the way that I'll describe to you.

23
00:03:45.510 --> 00:03:52.260
Michael Franz: And that's one of the challenges of the excessive amounts of polling, we have today is finding good ways to archive these data and make them available.

24
00:03:52.890 --> 00:04:07.260
Michael Franz: To us, but when we had this sort of Time series open to us back to 1948 Gallup has been asking about presidential approval for for for this length of time.

25
00:04:07.950 --> 00:04:16.620
Michael Franz: And they can split the responses into whether or not the party of the responded the party identification of the responded matches the party of President

26
00:04:17.190 --> 00:04:27.090
Michael Franz: And so the bold line there is what what I call own partisans which is the President's members of the President's party and approval ratings of those respondents of the President.

27
00:04:27.750 --> 00:04:38.130
Michael Franz: Which you'll bounced all around. But generally, hover around 75% approval rating can go much below that, but can also go much above that.

28
00:04:38.730 --> 00:04:49.320
Michael Franz: And but as always higher than out partisans those would be members of the other party. So in the case of Ronald Reagan out partisans would be Democrats democratic respondents in the poll

29
00:04:50.040 --> 00:04:58.740
Michael Franz: And when Brock Obama was president out partisans would be republicans and this is the approval rating of the president by out partisans as well, which

30
00:04:59.100 --> 00:05:08.130
Michael Franz: bounces around a lot as well can go way up in the case of right after 911 when everybody approved of George W. Bush.

31
00:05:08.580 --> 00:05:17.490
Michael Franz: But can also go way down to below 10% especially. More recently, and so the reason why I say polling is very valuable is because

32
00:05:17.910 --> 00:05:30.300
Michael Franz: One of the things we can see is the intense polarization that exists today from roughly the time that brock obama was inaugurated in this first part of 2009 Republicans had a brief moment of

33
00:05:30.690 --> 00:05:42.720
Michael Franz: Approving him at greater than 25% those numbers have plummeted to 10% or even less well own partisans don't have historic approval of their

34
00:05:43.020 --> 00:05:54.570
Michael Franz: Of the President in their party but have pretty high approval. And in fact, the difference between own partisans and out partisans in the last 12 years or 10 years or so in this graph.

35
00:05:55.020 --> 00:05:58.680
Michael Franz: Is greater than at any time in the history of the polling that Gallup has done.

36
00:05:59.190 --> 00:06:08.970
Michael Franz: And so the polarization between parties amongst Members of the electorate and how they evaluate the president is at historic highs and we can tell that from this graph.

37
00:06:09.810 --> 00:06:22.950
Michael Franz: Now that also means that this is one of the benefits of polling. It's one of the advantages of of being able to ask similar questions of respondents across many years of data.

38
00:06:23.910 --> 00:06:37.020
Michael Franz: Polling is also very valuable because it can tell us about trends in a race. This is Clinton versus Trump and 2016 we've seen some of this data before from the Identity Politics book and

39
00:06:37.860 --> 00:06:48.540
Michael Franz: It aggregates all the polls that asked about the head to head Trump versus Clinton battle in 2016 all the way back to when pollsters started asking about Clinton versus Trump

40
00:06:49.020 --> 00:07:02.460
Michael Franz: Soon after Trump was a declared candidate some pollsters asked, well, if Trump were to be the nominee, who would you vote for. And so anything above zero shows Clinton getting a higher support amongst the population than Trump

41
00:07:03.120 --> 00:07:13.770
Michael Franz: And the black line is a sort of what we call a Lois fit, which is a sort of line that allows the trend kind of finds the mean of the trend.

42
00:07:14.370 --> 00:07:19.260
Michael Franz: As you move along time. Now this is a form of polling aggregation.

43
00:07:20.040 --> 00:07:32.700
Michael Franz: And you want to look in the article about how she describes polling ALEC aggregation because I'm not looking at one poll. I'm looking at a summary measure of all the polls. But this black line doesn't actually account for

44
00:07:33.360 --> 00:07:42.810
Michael Franz: Various features of the polls itself. It doesn't account for sample size doesn't account for the type of poll being conducted with the type of population being surveyed

45
00:07:43.200 --> 00:07:46.290
Michael Franz: It just looks at all the polls and basically takes the moving average.

46
00:07:46.800 --> 00:07:54.990
Michael Franz: There's certain advantages of doing that as a hilarious points out, and then there are certain challenges of doing that kind of aggregation is as his biggest points out,

47
00:07:55.890 --> 00:08:11.250
Michael Franz: But even taking a very, very simple moving average of these polls over time. You can see that Clinton had a consistently throughout the entire campaign. When polls asked about a head to head matchup between the two. But that at the end, the campaign moved

48
00:08:12.330 --> 00:08:24.210
Michael Franz: Towards Trump but ended at a rest of the final black.on this line here is pretty darn close to the green dot, which is the actual national popular vote result.

49
00:08:24.750 --> 00:08:36.630
Michael Franz: And so even though at the end of the campaign, there was movement towards Trump which identity politics tells us may have been the consequence of the Kony letter or maybe not or access hollywood tapes or

50
00:08:37.350 --> 00:08:47.340
Michael Franz: The debates, there was some movement towards Trump at the very end, but all the polls generally predicted that Clinton still would win the national popular vote.

51
00:08:48.090 --> 00:08:59.310
Michael Franz: She did. And the very simple moving average fit to this line predicts the outcome. And just a little bit higher than the 2% win that she got the national popular vote.

52
00:08:59.700 --> 00:09:03.810
Michael Franz: So in that sense, the national polling was pretty accurate in 2016

53
00:09:04.350 --> 00:09:14.490
Michael Franz: That's taking into account a lot of variation here in this plot, you can see some polls had Trump winning samples that Trump winning this far back. But if we wait them.

54
00:09:14.910 --> 00:09:20.310
Michael Franz: And look at the moving average, we see that on average Clinton had a consistent lead

55
00:09:20.730 --> 00:09:31.440
Michael Franz: That's the advantage of polling aggregation. We don't focus on one poll or two poles, we allow all the polls to contribute to an inference that we make about the state of the race.

56
00:09:32.430 --> 00:09:43.590
Michael Franz: But let's not get too carried away here because polls can get things wrong. And in fact, at the state level, as we know from the discussion and identity crisis.

57
00:09:44.580 --> 00:09:56.310
Michael Franz: This is where they tended to get things a little bit wrong now not dramatically wrong but wrong enough to predict the outcome wrong. And so these are the polls in the state of Wisconsin.

58
00:09:56.910 --> 00:10:05.130
Michael Franz: And there are fewer polls in the state of Wisconsin. As you can see from the previous graph. There's just not as much effort put into state level polling, as there is national polling.

59
00:10:05.760 --> 00:10:17.400
Michael Franz: But early on in the campaign Clinton was absolutely far ahead of Trump, but over the course of the entire campaign primary into the general election. You can see that the race types. And in fact,

60
00:10:17.730 --> 00:10:24.540
Michael Franz: All of the polls suggests, or most of the polls suggest movement towards very competitive racing in Wisconsin.

61
00:10:24.960 --> 00:10:42.060
Michael Franz: Some of the final polls in the state over here predicted a Clinton when in Wisconsin by a couple of points, but all of the polls are above the zero line on this axis here, which means that all of the polls predicted the point estimate anyway predicted that Clinton would win the state.

62
00:10:43.470 --> 00:10:59.490
Michael Franz: Here's the final result which is that Trump won the state. And so in reality the polls were wrong. They were off, I should say they didn't predict the outcome correctly. Even the final polls, which showed a more competitive race that had been the case in the summer of

63
00:11:00.900 --> 00:11:12.630
Michael Franz: Of 2016 all tended to think that Clinton was likely to win the state of Wisconsin. So the polls ran into a problem in in 2016 at the state level.

64
00:11:15.060 --> 00:11:18.780
Michael Franz: But that may not have been a polling problem that may have been

65
00:11:19.380 --> 00:11:30.930
Michael Franz: A problem of picking up late movement in voters decisions. So, for example, these are, this is a graph from exit poll data. And so we'll talk about exit polls next week.

66
00:11:31.350 --> 00:11:45.180
Michael Franz: But the exit polls are administered in many of the key states, not every state, but in many of the key states and they're conducted at the polling places and increasingly the exit poll does some PRE ELECTION telephone poles.

67
00:11:45.990 --> 00:11:54.870
Michael Franz: But it's an assessment of who people voted for and and why they voted the way they did. So these data are aggregated to the state level.

68
00:11:55.320 --> 00:12:04.410
Michael Franz: And you have the state of Wisconsin highlighted up here and it shows on the X axis, the percentage of people in the exit poll. Who said they made the decision of who they were going to vote for

69
00:12:04.740 --> 00:12:10.410
Michael Franz: In the final week of the campaign. So who waited till the very, very end to decide who they were going to vote for

70
00:12:11.490 --> 00:12:18.540
Michael Franz: And in Wisconsin anyway about 15% of people who took the exit poll. So a pretty what we would refer as a

71
00:12:19.740 --> 00:12:31.950
Michael Franz: Rough percent of the populate voting population who decided late about 15% and it shows the Trump lead in the final declared vote of those voters over Clinton.

72
00:12:32.550 --> 00:12:39.510
Michael Franz: And you can see that in Wisconsin. Anyway, the undecided voters. Those who broke who'd made up their mind at the very end.

73
00:12:40.320 --> 00:12:49.350
Michael Franz: Tended to favor Trump by a lot. And that's a trump minus Clinton margin would say that the balance of people prefer Trump over Clinton.

74
00:12:49.800 --> 00:12:55.260
Michael Franz: In Wisconsin among the people who made their decision late, which was about 15% of the electorate.

75
00:12:55.710 --> 00:13:05.340
Michael Franz: So in this graph up here before you know we have undecideds that are not included in the graph. It's Clinton lead over Trump. So the percentage of people who would vote for Clinton.

76
00:13:05.640 --> 00:13:14.040
Michael Franz: Minus the percentage of people who would vote for Trump, and we assume that the undecided voters will break about evenly, since they're undecided. They're probably a flip a coin.

77
00:13:14.820 --> 00:13:23.790
Michael Franz: But in fact in Wisconsin, as in many other states the Wisconsin voters who decided they didn't flip a coin, they voted disproportionately for Trump.

78
00:13:24.150 --> 00:13:32.340
Michael Franz: And so the polls wouldn't pick that late movement up and so, to some extent, it's possible that the results in Wisconsin. We're not mistakes of the pollsters

79
00:13:32.670 --> 00:13:41.730
Michael Franz: Although we'll see some evidence of possible mistakes in a minute. But I've just late movement towards Trump that helped him win those states.

80
00:13:42.240 --> 00:13:52.050
Michael Franz: And that's important, important to keep in mind is that if a poll is conducted with three or four days left in the campaign and there's still five or 6% undecided.

81
00:13:52.680 --> 00:14:04.500
Michael Franz: In that race, if they break one way or the other, they'll typically race one direction or the other. And even though most people have already made up their mind. Not everybody has. And in a close race that can make a big difference.

82
00:14:06.480 --> 00:14:17.820
Michael Franz: And give you another example. This is in the context of the UK and the vote on Brexit. These are all the polls conducted by various organizations collected by the BBC.

83
00:14:18.780 --> 00:14:26.430
Michael Franz: To get a sense of where voters were on the Brexit issue, which was a referendum in the country. In the summer of 2016

84
00:14:27.210 --> 00:14:32.880
Michael Franz: And so this is the percent who would vote to leave the EU minus the percent who would vote to remain in the EU.

85
00:14:33.480 --> 00:14:51.000
Michael Franz: The final tally was to leave, which is created a whole series of problems for the country in the last number of years by about a couple points, but you can see that most of the polls over time predicted that or at least the moving average predicted that a large number of voters or

86
00:14:52.020 --> 00:15:04.050
Michael Franz: Advanced majority of the voters favored remain. Now there was some late movement towards the leaf side of things, but the final result. Using this moving average.

87
00:15:04.410 --> 00:15:09.210
Michael Franz: Predicted even though there was some polls above zero, but the moving average simple moving average would predict.

88
00:15:09.630 --> 00:15:23.430
Michael Franz: That the UK would vote to remain in the EU, and it didn't it voted to leave. And so this was also considered to be a bit of a polling failure, a difference in the sort of final weighted sort of aggregation against the result.

89
00:15:25.170 --> 00:15:33.750
Michael Franz: But we also have a an issue with undecideds here as well. This just shows in the same set of polls the percentage of voters who said at the time they were pulled

90
00:15:34.230 --> 00:15:41.310
Michael Franz: That they are undecided. And so for each of these polls, which is a great dot. You can see that in this sort of moving average.

91
00:15:41.790 --> 00:15:49.230
Michael Franz: Somewhere between 15 and 20% sometimes a lot higher of respondents were undecided on the issue of

92
00:15:49.590 --> 00:16:03.660
Michael Franz: Leave versus remain and that number have dropped a bit by the end of the campaign. But even at the very end, on average, the polls show that about one in 10 voters didn't know what they were going to do when they went in and voted.

93
00:16:04.200 --> 00:16:19.740
Michael Franz: And again, maybe one in 10 of those voters is enough to move the result from the poll which was just looking at 2% that's a remain minus the percent that say leave in the direction of leave the EU and so

94
00:16:20.850 --> 00:16:31.800
Michael Franz: We have to keep in mind undecideds we often assume that they don't exist anymore or that they will break evenly between the two options that they have. But that's not always it's not always the case.

95
00:16:33.180 --> 00:16:40.770
Michael Franz: So I want to talk about what I think are the main features of polling, the things we need to take stock of

96
00:16:41.220 --> 00:16:49.860
Michael Franz: And walk us through some of those some of those challenges. The first is going to be the mode of the poll. Which is sort of how it's conducted. Is it a telephone pole or an interface poll

97
00:16:50.430 --> 00:16:57.240
Michael Franz: How we could select our samples, how many people we interview response rates. How many people refuse to take our poll

98
00:16:57.870 --> 00:17:03.900
Michael Franz: We can wait. The results on the back end to try to make the demographics of the pole reflect the underlying population.

99
00:17:04.830 --> 00:17:11.190
Michael Franz: Not all pollsters do the same thing, the same way. And so we have what are called sponsor effects or what the article calls house effects.

100
00:17:11.790 --> 00:17:19.350
Michael Franz: And then, of course, to go back to that cartoon. We have the question wording problem which is we need to ask good questions in order to get good data.

101
00:17:20.100 --> 00:17:28.290
Michael Franz: So what about mode well mode is how we conduct the pole and the best polls are conducted by telephone, those are telephone poles.

102
00:17:28.740 --> 00:17:35.850
Michael Franz: And that's because that's a good way of reaching all voters in fact all of us have phones.

103
00:17:36.630 --> 00:17:48.840
Michael Franz: It wasn't always the case that all households or headphones back in the 50s and 60s, especially in rural areas, but everyone today has a phone or has access to a phone. And so to reach everybody we can do with

104
00:17:49.680 --> 00:18:02.280
Michael Franz: With calling them. We don't have a list of all voters an easy accessible list of all voters, more or less, are all adults pulsars don't have those pieces of information. So we can't sample from

105
00:18:03.330 --> 00:18:12.090
Michael Franz: A list like we would if we had a list of all Bowden students. I could sample 500 names from the list of bonus students that whatever random sample of students.

106
00:18:12.420 --> 00:18:19.140
Michael Franz: We don't have a list of all adults in the United States. And so we can't sample from the list, but we can sample from telephone numbers.

107
00:18:19.770 --> 00:18:28.950
Michael Franz: Which are broadly accessible to everybody. And we do that by sampling from area codes which will give us areas of the country that we can sample from

108
00:18:29.460 --> 00:18:38.640
Michael Franz: The prefix, which is the first three digits and telephone number, which the telephone companies to sign some prefixes to businesses and some prefixes to

109
00:18:39.600 --> 00:18:46.650
Michael Franz: Residences and we know what those are. And so we can sample from residential prefixes. So we have a random sample of areas.

110
00:18:47.040 --> 00:18:50.670
Michael Franz: A random sample random sample of residential phone lines.

111
00:18:51.090 --> 00:19:04.890
Michael Franz: And then the line number is just a random set of numbers that the phone company produces. And so we can randomly sample four digit numbers. And if we do that, we give everybody a chance to be in the poll which is important to get a good random sample.

112
00:19:06.060 --> 00:19:17.430
Michael Franz: Now, back in the old days, the golden era as I would call it, which was maybe the 80s. Every, every house generally had a phone. The vast majority of houses had only one and

113
00:19:19.350 --> 00:19:26.880
Michael Franz: And people tended to answer the phone. Well that started to change pretty quickly, many households got more than one landline

114
00:19:27.330 --> 00:19:36.240
Michael Franz: And people started to get cell phones now that changes how accessible. People are if you're older and you live in a house with just one old fashioned telephone line.

115
00:19:36.750 --> 00:19:38.790
Michael Franz: You have that chance of being sampled

116
00:19:39.360 --> 00:19:46.470
Michael Franz: If you're a younger person who lives at home, where there's a landline or two in your house and you have a cell phone, you might have way more chances to get sampled

117
00:19:46.770 --> 00:19:56.160
Michael Franz: Under this process of sampling phone numbers. So that makes you more likely to be pulled than an older person. And that's not good in terms of collecting a random sample of people

118
00:19:57.210 --> 00:20:08.730
Michael Franz: So the gold standard was this sort of perhaps the 70s and 80s when phones were accessible not widely distributed, at least not overwhelmingly the case that people had more phones than homes.

119
00:20:09.840 --> 00:20:20.250
Michael Franz: But now we're in a different world. In particular, the role of cell phones. Some pollsters do not sample from cell phone numbers because for lots of reasons.

120
00:20:21.330 --> 00:20:24.930
Michael Franz: They're harder to get a list of those cell phone numbers and

121
00:20:25.530 --> 00:20:36.360
Michael Franz: The law requires that cell phone polling a polling of people with cell phones, be done by live interviewers, and so if you're a pollster, who wants to sample cell phones.

122
00:20:36.630 --> 00:20:44.430
Michael Franz: You have to hire people to make the phone calls. Many pollsters have switched to what they call it VR polling, which is essentially

123
00:20:44.640 --> 00:20:52.770
Michael Franz: The computer randomly calls you and you are prompted to answer questions by pressing one, two or three on your phone and you never talk to a person

124
00:20:53.610 --> 00:21:00.990
Michael Franz: But that can only be done for landlines to hire people to make those phone calls makes administering the pole more costly.

125
00:21:01.680 --> 00:21:09.630
Michael Franz: And so if we want to include cell phones, we need to hire people to do that pay them taxes pay them, you know, all sorts of, you know, all sorts of

126
00:21:10.110 --> 00:21:12.630
Michael Franz: Things that come with hiring contract work.

127
00:21:13.410 --> 00:21:15.660
Michael Franz: I can also raise the cost of the pole. As a result,

128
00:21:15.990 --> 00:21:25.920
Michael Franz: But we have to include cell phones if we want to reach the population. And this is an old graph from Pew Research Center that goes back seven years. And so imagine where it would be today.

129
00:21:26.250 --> 00:21:37.200
Michael Franz: That looks at the percentage of adults in various categories that are in cell phone only households. I'm in a cell phone only household. We don't have a landline in my house and that's increasingly popular

130
00:21:37.920 --> 00:21:45.420
Michael Franz: And it varies across age groups and poverty status. And so if I don't put cell phone numbers in my poll

131
00:21:46.080 --> 00:21:50.520
Michael Franz: I will be missing disproportionately large segments of the population increasingly

132
00:21:51.090 --> 00:22:02.700
Michael Franz: And so if I want to sample by telephone, I have to put cell phone numbers in my sample which means I have to use a polling company that employs individuals to make those calls. Now, make it more expensive.

133
00:22:03.600 --> 00:22:09.510
Michael Franz: The other problem with cell phones is that they're transferable as you move. And so, it used to be the case.

134
00:22:10.140 --> 00:22:20.820
Michael Franz: With area codes that if I randomly call the 207 number I would reach a household in me. So if I wanted a sample main voters, I would only use 207 numbers.

135
00:22:21.480 --> 00:22:31.680
Michael Franz: Well, nowadays people move and they don't change their phone number. So I might sample cell phones with 207 area codes and I might get people who no longer live in the state of Maine.

136
00:22:32.430 --> 00:22:39.330
Michael Franz: And that makes it more costly because now I need to call another number to try to replace that sample person with a new sample person.

137
00:22:39.690 --> 00:22:49.530
Michael Franz: And so, cell phone coverage and the movement mobility of voters with those numbers makes it harder to assume that area codes are actually tied to geographic areas.

138
00:22:50.520 --> 00:22:58.260
Michael Franz: This is a big problem. This is a big problem. So what folks have tended to do is switch to internet based polling.

139
00:22:58.590 --> 00:23:05.190
Michael Franz: Now this is not the internet based poll and you might see on the Drudge Report or on CNN where you're asked to say who won the debate.

140
00:23:05.730 --> 00:23:16.530
Michael Franz: This is a an attempt to try to reproduce random sampling, but using the internet. Now that's hard to do because we don't have a list of emails that we can just sample from

141
00:23:17.250 --> 00:23:28.740
Michael Franz: But what we can do is try to build a large panel of people who are interested in participating in online polls. The most commonly used.

142
00:23:29.190 --> 00:23:45.990
Michael Franz: Vendor for this is a company called you Gov. And you can look them up if you like. You gov works as follows. If you sign up and you can sign up, you will become a member of you. GOV who will be sampled on occasion to take a poll

143
00:23:47.430 --> 00:23:54.360
Michael Franz: Why would you do that. Well, you would do that one right because you're interested in taking polls, but also in taking polls, you can earn points.

144
00:23:54.840 --> 00:24:05.310
Michael Franz: And those points can be used to redeem them for gift cards or for airline miles or for other sorts of things. So you gain a benefit by contributing to these polls.

145
00:24:05.730 --> 00:24:14.130
Michael Franz: You go tries to get as many people as they possibly can to select into their sample and they claim to have over a million people who are in their sample.

146
00:24:14.970 --> 00:24:31.440
Michael Franz: Then they sample from the panel. Let's say there's a million people in their category of panelists. They sample randomly from those individuals, which all of which provide an email address too much to be contacted and they administer the poll to the sample from the panel.

147
00:24:32.790 --> 00:24:44.130
Michael Franz: That makes it look kind of analogous to a random sample of voters. It's just a random sample of panelists. This is good. If the panel is really big because

148
00:24:47.760 --> 00:25:04.680
Michael Franz: There's a lot of people in there to sample from maybe millions, but it is not the same as sampling from the underlying population of all voters. It's sampling from a population of panelists, which is used to sort of stand in, if you will, for the broader population.

149
00:25:06.210 --> 00:25:08.760
Michael Franz: But it's creative and it allows

150
00:25:10.110 --> 00:25:21.630
Michael Franz: People to administer polls more quickly internet based polling can go faster. It can get responses more quickly because people tend to respond to these emails, especially when they're earning points.

151
00:25:22.200 --> 00:25:26.550
Michael Franz: They don't tend to answer their phone anymore. And that makes it harder to call people on the phone.

152
00:25:26.910 --> 00:25:39.810
Michael Franz: And so internet based polling has really become much more popular and you'll see in the polling aggregations especially with 538 that you Gov. Is there quite a bit. Now the other advantage of internet polls.

153
00:25:41.850 --> 00:25:45.150
Michael Franz: Is supposedly. It allows people to answer more accurately.

154
00:25:45.690 --> 00:25:54.450
Michael Franz: Supposedly, because when you're answering an internet based poll, you're not actually talking to a human being. And so you don't feel pressure to conform to certain social norms.

155
00:25:55.080 --> 00:26:02.280
Michael Franz: You can say what you really believe if you're a racist, you can express those racial views, but if you're talking to someone on the phone. Oftentimes, people have

156
00:26:02.880 --> 00:26:11.820
Michael Franz: hesitancy and in making known that they hold prejudicial views they hold them secretly or only reveal them selectively to friends and family members.

157
00:26:12.480 --> 00:26:20.880
Michael Franz: But on an online poll. There's nobody listening to your answers. You can just click the box as you want. And this was seen as a possible way of picking up

158
00:26:21.570 --> 00:26:26.670
Michael Franz: Support for Brexit amongst maybe UK voters who are afraid to admit they want to leave the EU.

159
00:26:27.120 --> 00:26:36.450
Michael Franz: And there's also a tendency for some folks to think that there's a shy Trump voter people who are afraid to admit they vote for Trump, because of his

160
00:26:37.020 --> 00:26:45.330
Michael Franz: brashness but who will admit it on an internet based poll so we can kind of look for that and test for that by comparing polls across modes.

161
00:26:47.550 --> 00:27:07.230
Michael Franz: Here's the Brexit results. The percent who say leave versus the percent who say remain in dark, the black ones are online based polls and you can see how prevalent and important they are to British politics, they're much more frequent today in British politics than telephone based polls.

162
00:27:08.550 --> 00:27:19.980
Michael Franz: Excuse me, but the internet based polls tended to predict a much closer race in the Brexit vote than the telephone poles. Did the telephone poles picked up late movement towards the leaf position.

163
00:27:20.940 --> 00:27:32.670
Michael Franz: But the internet based polls tended to maybe more accurately reflect that percentages of British voters wanted to leave the EU and in fact the moving average of the final

164
00:27:33.540 --> 00:27:49.410
Michael Franz: online polls of Brexit tended to be closer to the moving average of the final telephone based polls and predicted a leave vote instead of romaine boat. And so, to some extent, the online polls are a bit more accurate than the telephone baseball's

165
00:27:50.550 --> 00:27:58.050
Michael Franz: What about the shy Trump voter here. I've done a little slight of hand for you, which is I've taken the internet polls and now made them gray.

166
00:27:58.350 --> 00:28:09.960
Michael Franz: And the telephone poles made them black I should keep things consistent, but I didn't. So I apologize for that. Here you can see the clinton lead over Trump over time against the

167
00:28:10.980 --> 00:28:18.270
Michael Franz: Against the time and then split by the mode of the pole internet versus live telephone calls

168
00:28:18.780 --> 00:28:28.530
Michael Franz: And you can see here that, well, there's not a tremendous amount of evidence here for shy Trump voters in fact the internet based polls the moving average of internet based polls.

169
00:28:28.920 --> 00:28:36.630
Michael Franz: Tended to predict a higher Clinton lead than she actually got and it was the telephone poles that predicted a closer race.

170
00:28:37.410 --> 00:28:50.760
Michael Franz: And so if the shy Trump voters were only expressing support for Trump in the internet polls, then that shouldn't be the case in this graph, but the the numbers track pretty closely, there's a bit of a gap here in

171
00:28:51.930 --> 00:29:09.360
Michael Franz: The very end. This is from September of 2016 till November. So the very final two months, there's a bit of a gap here in October of 2016 that doesn't isn't as big as the other parts of the fall campaign, but by and large they track pretty well together and

172
00:29:10.500 --> 00:29:16.470
Michael Franz: The final moving average point on these graphs predicts Clinton winning the popular vote in both cases.

173
00:29:17.100 --> 00:29:24.150
Michael Franz: So I don't know much about a shy Trump drone photo effect. In fact, subsequent research hasn't much found any evidence for that.

174
00:29:24.870 --> 00:29:39.120
Michael Franz: But that was one of the hypotheses about the advantages of doing internet based polls. So we definitely want to take account of mode issues and find out whether a poll is conducted online versus conducted

175
00:29:40.500 --> 00:29:51.870
Michael Franz: by phone. The second issue a sample selection, typically with political polls were interested in one of three categories all adults, which is easy. We asked a respond. And if there are over the age of 18

176
00:29:52.470 --> 00:29:56.550
Michael Franz: registered voters, which is also pretty easy. We asked voters if they're registered to vote.

177
00:29:57.450 --> 00:30:04.650
Michael Franz: But we might be most interested in likely voters, which is people who claim that they are likely to vote and we leave out the people who claim that they're unlikely to vote.

178
00:30:05.370 --> 00:30:11.760
Michael Franz: Because of their I'm likely to vote, then we don't want them to influence the prediction of who will win the election because they're not going to vote.

179
00:30:12.000 --> 00:30:22.560
Michael Franz: So we're only interested in the people who say they're likely to vote. But what is a likely voter analogous talks about this is operationalize differently across different surveys

180
00:30:23.100 --> 00:30:30.570
Michael Franz: We could just ask people how likely are you to vote and then only include in our results. People who say that they are definitely likely to vote.

181
00:30:30.930 --> 00:30:42.090
Michael Franz: But what about people who say they will probably vote should they be included in the category of likely voter and how the results change if we define likely voter in different ways. That's kind of a conceptual

182
00:30:42.900 --> 00:30:50.670
Michael Franz: Challenge for pollsters it does matter a little bit in the results. This is a what we call a box plot of

183
00:30:51.630 --> 00:30:57.720
Michael Franz: Support for the Democrats or Republicans in who should control the US House in 2016

184
00:30:58.170 --> 00:31:07.380
Michael Franz: It's called the generic congressional balance. So we oftentimes ask pull people off. Oftentimes asked, Who do you want to be in charge of the US House Democrats or Republicans sort of a generic question.

185
00:31:07.950 --> 00:31:20.310
Michael Franz: Well, if you ask likely voters. The line here in this box is the median of all the polls. So this is another way to aggregate polling results. Not looking across time, but sort of lumping them all into one.

186
00:31:20.640 --> 00:31:31.320
Michael Franz: Bucket amongst likely voters. The median support for Democrats is about 40% the median support for Republicans, a little bit less than that. And so the lead on average the median lead

187
00:31:31.650 --> 00:31:41.370
Michael Franz: between Democrats and Republicans in the likely voters is pretty close but amongst registered voters democrats are far more preferred to Republicans, then

188
00:31:42.450 --> 00:31:50.700
Michael Franz: Then in the likely voter set. And so looking at registered voters would suggest that Democrats are doing really well. Looking at likely voters suggest there's

189
00:31:51.060 --> 00:31:55.890
Michael Franz: Almost a split of support between Democrats and Republicans over who should control the House.

190
00:31:56.190 --> 00:32:00.600
Michael Franz: And so looking at likely voters versus looking at registered voters will give us different sets of results.

191
00:32:00.870 --> 00:32:13.440
Michael Franz: You'll see that in 538 and Real Clear Politics some polls are polls have what they call lbs likely voters and some polls are of Arby's registered voters and so we just need to know and pay attention to that.

192
00:32:15.330 --> 00:32:25.110
Michael Franz: The third issue is sample size. In short, more data is better. We want more data. But there's an interesting, interesting decision or interesting consequence of that.

193
00:32:25.500 --> 00:32:27.960
Michael Franz: You've heard about margins of error, where a poll says

194
00:32:28.830 --> 00:32:41.880
Michael Franz: Clinton is beating Trump or Biden is beating Trump by four points plus or minus three that margin of error gives us a sense of how certain we are in the results and it's purely a function. Well, it's almost purely a function of sample size.

195
00:32:42.720 --> 00:32:53.670
Michael Franz: It's also a function of the proportions, but sample sizes key. And so when you have a small sample your uncertainty is pretty large. You only asked 10 people we don't really know how well a reflection. Is that a

196
00:32:54.360 --> 00:33:03.420
Michael Franz: broader public. But if we ask 1000 people the sample size starts to drop and it drops really fast from 10 people up to 1000 people

197
00:33:03.840 --> 00:33:11.220
Michael Franz: But what you're saying about sample sizes. It doesn't get much smaller when you move from 2000 to 3000 or from 5000 to 6000

198
00:33:11.580 --> 00:33:20.610
Michael Franz: it bottoms out at you know maybe one or two points because we never know the truth, for sure, but it doesn't get much better. Once you get past 1000

199
00:33:21.000 --> 00:33:35.130
Michael Franz: And so most polls will be of 1000 people maybe 500 or 750 because it's expensive to pull people and because if I doubled my budget and tried to increase my pole from 1000 to 2000 my margins of error would not get

200
00:33:36.000 --> 00:33:41.760
Michael Franz: Double the small and so that's why most polls tend to cluster in the thousand range.

201
00:33:42.390 --> 00:33:49.380
Michael Franz: So sample sizes and point you want to pay attention to sample size. If you see a poll conducted in your race with a sample size of around 200

202
00:33:50.010 --> 00:33:58.530
Michael Franz: You know, you want to be some suspicious of that because the margin of error is going to be a lot bigger than if it was 1000 that's where the movement really is in the margin of error.

203
00:34:00.570 --> 00:34:06.750
Michael Franz: response rates are increasingly important, because they're increasingly bad response rates are

204
00:34:08.460 --> 00:34:18.660
Michael Franz: A huge problem for us. These days, when we conduct polls fewer and fewer people want to answer their phone. And so you can look at this, but looking at some data between 1997 and 2012

205
00:34:19.500 --> 00:34:28.230
Michael Franz: The response rate is the percent of households who are sampled that yield in an interview. There's a percent of households where someone was reached, which is the contact rate.

206
00:34:28.860 --> 00:34:42.540
Michael Franz: The percentage of households that contacted the yield interview. So a subset of those and then the response rate is the final number of people called that actually produced a survey.

207
00:34:43.710 --> 00:34:56.730
Michael Franz: And in 1997 the response rate was about 36% of people sampled. But in 2012 the response rate for Pew surveys was only 9% which means that only one in 10 people that were sampled

208
00:34:57.420 --> 00:35:03.810
Michael Franz: yielded an interview. So if you want 1000 person survey in order to get that good margin of error around 3%

209
00:35:04.320 --> 00:35:09.840
Michael Franz: You need to interview or you need to sample 10,000 phone numbers that's 10,000 phone calls.

210
00:35:10.290 --> 00:35:17.610
Michael Franz: To get 1000 interviews. Now we don't just give up when somebody doesn't answer the phone. We usually call them three, four or five times before we give up.

211
00:35:17.940 --> 00:35:35.160
Michael Franz: So imagine you had to do that for every one of those 10,000 households. Now you've made 50,000 phone calls to get 1000 responses. If you're using cell phones you need live interviewers doing those phone calls. So you can imagine how costly things can get pretty quickly.

212
00:35:36.870 --> 00:35:45.450
Michael Franz: Now, not all send surveys have response rates that are 9%. Some have my response rates that are much higher. This is from the Economist

213
00:35:45.810 --> 00:35:52.140
Michael Franz: That shows the current population survey the General Social Survey, a variety of very commonly done surveys across time.

214
00:35:52.560 --> 00:36:00.660
Michael Franz: And response rates here are much higher and the current population survey is bit of a pest. They will track you down and make you fill out that survey.

215
00:36:01.260 --> 00:36:04.740
Michael Franz: They work for the census. So they are pretty good at tracking you down and they get

216
00:36:05.160 --> 00:36:15.090
Michael Franz: Pretty good response rates General Social Survey the consumer expenditures survey, they, they work really hard to get people to fill out their surveys. They don't give up very easily.

217
00:36:15.420 --> 00:36:25.230
Michael Franz: But response rates are still going down in all these cases, and that's a concern for us because it's expensive to get people to fill out surveys

218
00:36:27.240 --> 00:36:31.350
Michael Franz: And another reason why internet based polling is becoming more frequent because

219
00:36:31.740 --> 00:36:39.210
Michael Franz: Especially with you have all of the people they're sampling from are people who have said to you go, Yes, I want to take your polls, send them to me.

220
00:36:39.630 --> 00:36:49.020
Michael Franz: And I will get an earn points in filling them out and so response rates are through the roof for you. GOV because they're already sampling from a set of willing participants.

221
00:36:49.590 --> 00:36:56.730
Michael Franz: So if you're not going to use. You go and you want to use a telephone pole beware response rates are going to be really been a bit of a challenge.

222
00:36:57.540 --> 00:37:05.040
Michael Franz: Now waiting is more complex and I'm not going to go through much detail on waiting. But the short of it is that the responses we get back

223
00:37:05.490 --> 00:37:18.690
Michael Franz: Don't often look like the distribution of the electorate. So when we do a random sample of people, as long as people randomly say yes or randomly say no to taking our survey, then it's not a huge deal that we don't get

224
00:37:19.740 --> 00:37:26.040
Michael Franz: That you know that response rates are low, but what if older people are more likely to say yes and younger people are more likely to say no.

225
00:37:26.490 --> 00:37:33.390
Michael Franz: When they're asked to fill out a survey. Well then, older people would be over represented in the survey and younger people would be under represented

226
00:37:33.660 --> 00:37:39.900
Michael Franz: In the survey. Once we have our set of responses. That's bad because older people and younger people have different political views.

227
00:37:40.470 --> 00:37:50.370
Michael Franz: So we can wait things which is to count those older respondents, a little bit less and to count those younger respondents a little bit more and try to balance it out to the

228
00:37:51.030 --> 00:37:54.090
Michael Franz: underlying population distribution across age.

229
00:37:54.810 --> 00:38:06.870
Michael Franz: You can see that here in this graph, which uses the current population survey to look at the difference between the share of eligible voters and the share of actual voters in the 2012 election.

230
00:38:07.380 --> 00:38:16.950
Michael Franz: And this makes sense to us the black dots, show us the share of actual voters so 20% of the voting, pop, pop, public in 2012 was 55 to 64

231
00:38:17.520 --> 00:38:29.400
Michael Franz: However, the white.is the share of eligible voters, they're less of a share of eligible voters more of a share of actual voters and so these older voters are over represented amongst the electorate.

232
00:38:30.270 --> 00:38:37.050
Michael Franz: And younger voters who make up you know 13% of actual eligible voters showed up at lower than 10%

233
00:38:37.890 --> 00:38:51.540
Michael Franz: Or made up. I should say about 9% eight and a half percent of the voting public in 2012 so they are under represented in the share of actual voters. Well, we can get the same set of results with polls. And so what we can do is count.

234
00:38:52.770 --> 00:38:54.330
Michael Franz: The people here in this

235
00:38:54.780 --> 00:39:05.430
Michael Franz: blacked out we can count them more to make them wait up to this number and we can under count these folks, essentially, instead of counting everybody in the poll is one person we can count them as

236
00:39:05.640 --> 00:39:21.210
Michael Franz: 1.2 people and we can count them as point eight people and make them count less in the set of final results. It's like a weighted average weighted by the population distribution across these different demographic groups.

237
00:39:22.320 --> 00:39:29.100
Michael Franz: Waiting is something that pollsters will do in order to kind of even things out when they get a set of respondents. That doesn't look very much like

238
00:39:29.820 --> 00:39:42.060
Michael Franz: The population. They're trying to make inferences about but what await is is a decision by a pollster to fudge the numbers. And that's always a bit of a bit of a concern.

239
00:39:43.680 --> 00:39:54.240
Michael Franz: Perhaps the fact that pollsters did not fudge the numbers was something to do with the polling mistakes in 2016 and that's because it may have been the case that

240
00:39:54.990 --> 00:40:04.320
Michael Franz: In line with identity crisis working class white voters non college educated white voters may have been disproportionately less likely to

241
00:40:04.890 --> 00:40:14.070
Michael Franz: To answer the phone or to take a survey in 2016 and as a result they were not accurately reflected in the set of polling results.

242
00:40:15.060 --> 00:40:22.020
Michael Franz: If they weren't then the polls would undercount Trump's support in that state which is generally what happened.

243
00:40:22.350 --> 00:40:33.390
Michael Franz: And so this is a graph again from the economist that looks at the percent across states of voting eligible population that are lights with no college education and there's a similar graph to this.

244
00:40:33.810 --> 00:40:51.300
Michael Franz: In identity crisis and it shows that there are some states that have very high share of voting eligible voters voting eligible population that are these working class white voters, the x and y axis shows us how good or bad. The poll was relative to the outcome of the election.

245
00:40:52.320 --> 00:40:56.730
Michael Franz: In this case numbers that are greater than zero underestimated Trump's support.

246
00:40:57.540 --> 00:41:09.450
Michael Franz: And lo and behold, there's a pretty good relationship between how much a state has working class white voters and how under representative, the poll was of trumps support.

247
00:41:09.990 --> 00:41:19.290
Michael Franz: And in places with a lot of working class white voters. The polls were more wrong. And so it could have been the case that there was a response bias in the poll

248
00:41:20.130 --> 00:41:27.480
Michael Franz: We're working class whites did not take the polls at high enough rates to be included and reflect their support for Trump.

249
00:41:28.200 --> 00:41:46.710
Michael Franz: If pollsters knowingness or waited on that they might have emphasized or added more to the poll Trump's support from the working class white voters who did take the survey, but pollsters oftentimes don't wait on things like education and so they may have missed

250
00:41:47.730 --> 00:41:58.680
Michael Franz: That in the poll result. Now that we've been told that this is one of the things pollsters have fixed about 2016 is they now look specifically to see if their polls have

251
00:41:59.010 --> 00:42:16.290
Michael Franz: A proportionate number of working class white respondents in their poll. And if they don't, they wake them up to match these numbers in the state. And so we should see better results in 2020 than we did in 2016 at the state level because of that.

252
00:42:17.370 --> 00:42:18.300
Michael Franz: Is a huge problem.

253
00:42:19.440 --> 00:42:25.350
Michael Franz: We also have a sponsor based effects. So this is number six sponsor based effects are such that

254
00:42:26.940 --> 00:42:34.080
Michael Franz: Some polling companies have procedures that differ from other polling companies. We call them house effects or sponsor effects.

255
00:42:34.650 --> 00:42:42.510
Michael Franz: And they may be the way they define likely voters, they may have a proprietary way of defining likely voters have more complicated method of doing it.

256
00:42:42.870 --> 00:42:51.270
Michael Franz: They may ask the question in different ways and other pollsters asked the question, they may wait on different variables that other pollsters don't wait on

257
00:42:51.630 --> 00:43:00.570
Michael Franz: And so as a result, they may disproportionately or regularly have effects that are different than other pollsters. Here's an example. Rasmussen

258
00:43:01.950 --> 00:43:09.570
Michael Franz: Their polls are in black compared to all the other polls and what Rasmussen found is that over the course of the campaign.

259
00:43:09.930 --> 00:43:19.350
Michael Franz: It tended to show a very, very, very tight race at the national popular level between Clinton and Trump many of its polls showed Trump winning the popular vote.

260
00:43:19.920 --> 00:43:31.020
Michael Franz: Some polls showed Trump, Clinton winning the popular vote and on average it showed a very, very close race, whereas all the other pollsters tended to show Clinton in the lead.

261
00:43:32.550 --> 00:43:36.720
Michael Franz: So the difference between Rasmussen and all the others as a sponsor based effect. It's a consistent

262
00:43:37.320 --> 00:43:47.730
Michael Franz: Pro Trump bias, if you will, doesn't make it wrong. It just reflects the methodology Rasmussen uses, which we don't know all the differences between other pollsters

263
00:43:48.120 --> 00:43:55.590
Michael Franz: And we need to account for that. And you can actually go see this if you go to 538 and see the approval ratings for Trump over time.

264
00:43:55.950 --> 00:44:08.310
Michael Franz: Look at the Rasmussen polls even since he was inaugurated Rasmussen has tended to find approval ratings for Trump that are higher than a lot of the other polls, sometimes by 10 points. And that's a sponsor effect.

265
00:44:08.670 --> 00:44:16.710
Michael Franz: So we need to be aware of the possibility of these sponsor effects. They're not always easy to recognize, but they are potentially there.

266
00:44:18.210 --> 00:44:20.970
Michael Franz: And then of course the final issue is question wording.

267
00:44:21.570 --> 00:44:36.150
Michael Franz: I asked this question of Bowden students. A few years ago, when we did some polling a boat and students, which we do regularly in my quantitative analysis class and we asked this question, how do you evaluate the statement I feel safe expressing my political views on bowden's campus.

268
00:44:37.260 --> 00:44:45.480
Michael Franz: 37% said they agreed 16% said they strongly agreed 32% said they either disagreed or strongly disagree.

269
00:44:46.080 --> 00:44:52.740
Michael Franz: And you might take those results and say, Wow, a third of Bowden students don't feel safe expressing their views on campus. But what is safe mean

270
00:44:53.550 --> 00:45:03.690
Michael Franz: What I mean by safe. Do I mean physically safe intellectually safe mentally safe. What do I mean it's unclear and it could be unclear to the students taking the pole.

271
00:45:04.200 --> 00:45:13.230
Michael Franz: And so this is a question where I wouldn't say it's a bad question. I would say it's fraught with challenges when I asked it this way. I should be more clear. I want to meet about safe.

272
00:45:13.800 --> 00:45:28.950
Michael Franz: And I shouldn't make inferences about what safe means not knowing how students variable interpreted. My question. And so we need to be a pay attention to question wording and perhaps order where it fits in a survey in addition to all these mechanics of sampling and so forth.

273
00:45:31.770 --> 00:45:38.250
Michael Franz: So what does this all me. Why should we learn to love polls, given all of this. I think we should

274
00:45:38.640 --> 00:45:44.970
Michael Franz: I think we should be skeptical of them. But we shouldn't throw them out. We should use them as important and valuable evidence

275
00:45:45.330 --> 00:45:53.910
Michael Franz: For one polls make the stakes clear when an election is close in the polls show that we know that we need to pay attention to what's happening in that race.

276
00:45:54.210 --> 00:46:01.890
Michael Franz: We're seeing in South Carolina Lindsey Graham is now in a deadlock HEAD TO HEAD MATCHUP WITH Jamie Harrison, we know that from the polls.

277
00:46:02.160 --> 00:46:11.400
Michael Franz: And so as a result, voters in South Carolina are going to pay more attention the candidates are going to spend more money voters are going to get more informed about Harrison's views and grams views.

278
00:46:11.850 --> 00:46:20.070
Michael Franz: And I would say, by and large, the end of the day, voters will know more and make better decisions, given that they pay more attention and they pay more attention because the polls told them to

279
00:46:21.690 --> 00:46:33.360
Michael Franz: We also want to know more than just the election results we want to know why voters make the decisions they do we want to know what relationships are between certain variables and people's voter attitudes and behaviors.

280
00:46:34.200 --> 00:46:38.310
Michael Franz: Hilux talks about this at the end of her chapter or her paper and I think it's right.

281
00:46:38.580 --> 00:46:46.590
Michael Franz: If we just look at the results. We don't know why they happen. We don't know what people were thinking when they showed up at the ballot box or filled out their absentee ballot.

282
00:46:47.280 --> 00:46:56.310
Michael Franz: And so poll results allow us to tease that out by saying, Why did you vote for this candidate or look for relationships between demographic characteristics of voters and their behavior.

283
00:46:57.300 --> 00:47:05.400
Michael Franz: So we should be skeptical of polls. There's no question about that. But, and we should look for all these things that I've highlighted to you today.

284
00:47:05.880 --> 00:47:14.400
Michael Franz: But we shouldn't throw pulls out because of those challenges. We should try to become better consumers of poles. And I think that's the message that I'm trying to convey

285
00:47:15.030 --> 00:47:26.910
Michael Franz: And I want you to look at your polls, click on them dig into them read the methodology of the polls and your race and try to find out what they say about how they operationalize likely voters do they tell you

286
00:47:27.390 --> 00:47:42.060
Michael Franz: Did they wait, do they tell you what was the questions that they asked what wording, did they use their relationships between education race, gender, and the results that they highlight sometimes those are inside the results and not just

287
00:47:43.200 --> 00:47:53.580
Michael Franz: On the top line numbers that nate silver or Real Clear Politics gives us let's dig into those polls and let's learn a little bit more and be critical consumers of them.

288
00:47:54.510 --> 00:48:10.290
Michael Franz: So that's my message and I hope you enjoyed that and learn something and I look forward to talking about polls and digging into some of the results in your polls, so thank you. I hope you had a good break and I will talk to you soon.

